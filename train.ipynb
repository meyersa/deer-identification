{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B9oAcCxV15-J"
      },
      "outputs": [],
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"processed-images.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(\n",
        "        path=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEHFwPUM_q-E",
        "outputId": "3a2a3f0b-e240-431d-a63f-07feca242fa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-20 12:53:18.015036: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
            "2024-11-20 12:53:18.015084: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
            "2024-11-20 12:53:18.015092: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
            "2024-11-20 12:53:18.015503: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-11-20 12:53:18.015535: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/augustmeyers/Coding/deer-identification/.venv/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_8']. Received: the structure of inputs=('*', '*')\n",
            "  warnings.warn(\n",
            "2024-11-20 12:53:20.149376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.6397 - loss: 0.7990 - val_accuracy: 0.7042 - val_loss: 0.5833\n",
            "Epoch 2/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.7274 - loss: 0.5588 - val_accuracy: 0.6878 - val_loss: 0.5630\n",
            "Epoch 3/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.7604 - loss: 0.5402 - val_accuracy: 0.7441 - val_loss: 0.5281\n",
            "Epoch 4/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7513 - loss: 0.5165 - val_accuracy: 0.7488 - val_loss: 0.5308\n",
            "Epoch 5/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8125 - loss: 0.4707 - val_accuracy: 0.8122 - val_loss: 0.4208\n",
            "Epoch 6/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.7984 - loss: 0.4421 - val_accuracy: 0.7700 - val_loss: 0.4302\n",
            "Epoch 7/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8263 - loss: 0.3913 - val_accuracy: 0.8498 - val_loss: 0.3758\n",
            "Epoch 8/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8446 - loss: 0.3539 - val_accuracy: 0.8239 - val_loss: 0.3799\n",
            "Epoch 9/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8709 - loss: 0.3186 - val_accuracy: 0.8169 - val_loss: 0.4027\n",
            "Epoch 10/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8660 - loss: 0.3066 - val_accuracy: 0.8568 - val_loss: 0.3594\n",
            "Epoch 11/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8969 - loss: 0.2353 - val_accuracy: 0.8474 - val_loss: 0.3854\n",
            "Epoch 12/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9195 - loss: 0.2118 - val_accuracy: 0.8944 - val_loss: 0.3243\n",
            "Epoch 13/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9245 - loss: 0.1747 - val_accuracy: 0.8920 - val_loss: 0.3481\n",
            "Epoch 14/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9409 - loss: 0.1587 - val_accuracy: 0.8803 - val_loss: 0.3937\n",
            "Epoch 15/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9294 - loss: 0.1786 - val_accuracy: 0.8779 - val_loss: 0.3897\n",
            "Epoch 16/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9429 - loss: 0.1305 - val_accuracy: 0.9061 - val_loss: 0.3950\n",
            "Epoch 17/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9567 - loss: 0.1052 - val_accuracy: 0.9014 - val_loss: 0.3920\n",
            "Epoch 18/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9612 - loss: 0.0997 - val_accuracy: 0.8873 - val_loss: 0.4589\n",
            "Epoch 19/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.9677 - loss: 0.0810 - val_accuracy: 0.8638 - val_loss: 0.3868\n",
            "Epoch 20/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9692 - loss: 0.0876 - val_accuracy: 0.8920 - val_loss: 0.4929\n",
            "Epoch 21/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9695 - loss: 0.0747 - val_accuracy: 0.8897 - val_loss: 0.4389\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9055 - loss: 0.3984\n",
            "Validation Loss: 0.39504820108413696\n",
            "Validation Accuracy: 0.9061033129692078\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       159\n",
            "           1       0.93      0.93      0.93       267\n",
            "\n",
            "    accuracy                           0.91       426\n",
            "   macro avg       0.90      0.90      0.90       426\n",
            "weighted avg       0.91      0.91      0.91       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv('images.csv', header=None, names=[\"image_path\", \"label\", \"timestamp\", \"moon_phase\", \"wind\", \"weather\", \"temp\", \"humidity\", \"pressure\"])\n",
        "\n",
        "# Filter out rows where image paths do not exist\n",
        "df = df[df['image_path'].apply(os.path.exists)]\n",
        "\n",
        "# Convert timestamp to datetime with UTC conversion, with error handling\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True)\n",
        "\n",
        "# Drop rows with invalid timestamps (NaT)\n",
        "df = df.dropna()\n",
        "\n",
        "# Extract features from the timestamp\n",
        "df['hour'] = df['timestamp'].dt.hour  # Hour of the day\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek  # Day of the week\n",
        "df['is_night'] = (df['hour'] < 6) | (df['hour'] > 18)  # Simple binary night/day indicator\n",
        "\n",
        "# Handle categorical features (moon_phase, weather) with one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['moon_phase', 'weather'], drop_first=True)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['wind', 'temp', 'humidity', 'pressure']] = scaler.fit_transform(df[['wind', 'temp', 'humidity', 'pressure']])\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Image loading function with normalization\n",
        "def load_image(image_path, target_size=(224, 224)):\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return img_array.astype(np.float32)  # Ensure it's in float32 format\n",
        "\n",
        "# Load all images in parallel using ThreadPoolExecutor\n",
        "def load_images_in_parallel(image_paths, batch_size=32, target_size=(224, 224)):\n",
        "    images = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for i in range(0, len(image_paths), batch_size):\n",
        "            batch_paths = image_paths[i:i + batch_size]\n",
        "            batch_images = list(executor.map(lambda path: load_image(path, target_size), batch_paths))\n",
        "            images.extend(batch_images)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images and convert to NumPy array\n",
        "images = load_images_in_parallel(df['image_path'].values)\n",
        "\n",
        "# Extract features as a NumPy array\n",
        "metadata_columns = ['hour', 'day_of_week', 'is_night', 'wind', 'temp', 'humidity', 'pressure'] + \\\n",
        "                   [col for col in df.columns if col.startswith('moon_phase_') or col.startswith('weather_')]\n",
        "metadata = df[metadata_columns].values  # Convert to NumPy array\n",
        "metadata = metadata.astype(np.float32)  # Ensure float32 dtype\n",
        "\n",
        "# Convert the label to a NumPy array (binary classification: deer or not-deer)\n",
        "labels = (df['label'] == 'deer').astype(int).values  # Convert to 0 or 1 (0: not deer, 1: deer)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_images, X_val_images, X_train_metadata, X_val_metadata, y_train, y_val = train_test_split(\n",
        "    images, metadata, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the model with dropout and learning rate scheduler\n",
        "image_input = layers.Input(shape=(224, 224, 3))  # Shape of the images (224x224 RGB images)\n",
        "\n",
        "# Image model\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Combine image model and metadata\n",
        "metadata_input = layers.Input(shape=(metadata.shape[1],))  # Shape of metadata (after one-hot encoding)\n",
        "combined = layers.concatenate([x, metadata_input])\n",
        "\n",
        "# Add a fully connected layer, dropout for regularization, and output layer\n",
        "x = layers.Dense(128, activation='relu')(combined)\n",
        "x = layers.Dropout(0.5)(x)  # Dropout to reduce overfitting\n",
        "x = layers.Dense(1, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
        "\n",
        "# Define the model\n",
        "model = models.Model(inputs=[image_input, metadata_input], outputs=x)\n",
        "\n",
        "# Compile the model with a learning rate scheduler\n",
        "initial_lr = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_lr, decay_steps=10000, decay_rate=0.9, staircase=True\n",
        ")\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',  # Metric to monitor (e.g., 'val_loss' or 'val_accuracy')\n",
        "    patience=5,          # Number of epochs with no improvement to wait before stopping\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train_images, X_train_metadata],  # Input data (images and metadata)\n",
        "    y_train,  # Labels\n",
        "    validation_data=([X_val_images, X_val_metadata], y_val),  # Validation data\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping],  # Include the EarlyStopping callback here\n",
        ")\n",
        "\n",
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate([X_val_images, X_val_metadata], y_val)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_acc}\")\n",
        "\n",
        "# Predictions and classification report\n",
        "y_pred = (model.predict([X_val_images, X_val_metadata]) > 0.5).astype(int)  # Convert predictions to 0 or 1\n",
        "\n",
        "# Classification report (Precision, Recall, F1-Score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
