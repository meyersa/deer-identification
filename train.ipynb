{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B9oAcCxV15-J"
      },
      "outputs": [],
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"processed-images.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(\n",
        "        path=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vUjf3oShR53U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv('images.csv', header=None, names=[\"image_path\", \"label\", \"timestamp\", \"moon_phase\", \"wind\", \"weather\", \"temp\", \"humidity\", \"pressure\"])\n",
        "\n",
        "# Filter out rows where image paths do not exist\n",
        "df = df[df['image_path'].apply(os.path.exists)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fg6cg0DR_gY",
        "outputId": "ed36fc92-2ae6-4993-9faf-6bd1007cb8a6"
      },
      "outputs": [],
      "source": [
        "# Convert timestamp to datetime with UTC conversion, with error handling\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True)\n",
        "\n",
        "# Drop rows with invalid timestamps (NaT)\n",
        "df = df.dropna()\n",
        "\n",
        "# Extract features from the timestamp\n",
        "df['hour'] = df['timestamp'].dt.hour  # Hour of the day\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek  # Day of the week\n",
        "df['is_night'] = (df['hour'] < 6) | (df['hour'] > 18)  # Simple binary night/day indicator\n",
        "\n",
        "# Handle categorical features (moon_phase, weather) with one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['moon_phase', 'weather'], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FfIVHiJGSFZ1"
      },
      "outputs": [],
      "source": [
        "# Extract features as a NumPy array\n",
        "metadata_columns = ['hour', 'day_of_week', 'is_night', 'wind', 'temp', 'humidity', 'pressure'] + \\\n",
        "                   [col for col in df.columns if col.startswith('moon_phase_') or col.startswith('weather_')]\n",
        "metadata = df[metadata_columns].values  # Convert to NumPy array\n",
        "metadata = metadata.astype(np.float32)  # Ensure float32 dtype\n",
        "\n",
        "# Convert the label to a NumPy array (binary classification: deer or not-deer)\n",
        "labels = (df['label'] == 'deer').astype(int).values  # Convert to 0 or 1 (0: not deer, 1: deer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q6864GpySK0x"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Image loading function with normalization\n",
        "def load_image(image_path, target_size=(224, 224)):\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return img_array.astype(np.float32)  # Ensure it's in float32 format\n",
        "\n",
        "# Load all images in parallel using ThreadPoolExecutor\n",
        "def load_images_in_parallel(image_paths, batch_size=32, target_size=(224, 224)):\n",
        "    images = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for i in range(0, len(image_paths), batch_size):\n",
        "            batch_paths = image_paths[i:i + batch_size]\n",
        "            batch_images = list(executor.map(lambda path: load_image(path, target_size), batch_paths))\n",
        "            images.extend(batch_images)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images and convert to NumPy array\n",
        "images = load_images_in_parallel(df['image_path'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdssls3fSNyw",
        "outputId": "f60098ee-24e6-4170-ebfd-aa0161c690a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2129, 224, 224, 3) float32\n",
            "(2129, 16) float32\n",
            "(2129,) int64\n"
          ]
        }
      ],
      "source": [
        "# Ensure correct shape and dtype\n",
        "print(images.shape, images.dtype)  # Should be (num_samples, 224, 224, 3) and float32\n",
        "print(metadata.shape, metadata.dtype)  # Should be (num_samples, N) and float32 (N depends on one-hot encoding)\n",
        "print(labels.shape, labels.dtype)  # Should be (num_samples,) and int32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NjW1vKKSSTkr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_images, X_val_images, X_train_metadata, X_val_metadata, y_train, y_val = train_test_split(\n",
        "    images, metadata, labels, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KEHFwPUM_q-E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the model with dropout and learning rate scheduler\n",
        "image_input = layers.Input(shape=(224, 224, 3))  # Shape of the images (224x224 RGB images)\n",
        "\n",
        "# Image model\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Combine image model and metadata\n",
        "metadata_input = layers.Input(shape=(metadata.shape[1],))  # Shape of metadata (after one-hot encoding)\n",
        "combined = layers.concatenate([x, metadata_input])\n",
        "\n",
        "# Add a fully connected layer, dropout for regularization, and output layer\n",
        "x = layers.Dense(128, activation='relu')(combined)\n",
        "x = layers.Dropout(0.5)(x)  # Dropout to reduce overfitting\n",
        "x = layers.Dense(1, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
        "\n",
        "# Define the model\n",
        "model = models.Model(inputs=[image_input, metadata_input], outputs=x)\n",
        "\n",
        "# Compile the model with a learning rate scheduler\n",
        "initial_lr = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_lr, decay_steps=10000, decay_rate=0.9, staircase=True\n",
        ")\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "2GjOJancSa9k",
        "outputId": "7ad9096a-17c8-4868-a677-8a6b70aa997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 129ms/step - accuracy: 0.7394 - loss: 0.5402 - val_accuracy: 0.7418 - val_loss: 0.5685\n",
            "Epoch 2/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - accuracy: 0.7329 - loss: 0.5455 - val_accuracy: 0.7840 - val_loss: 0.4981\n",
            "Epoch 3/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 112ms/step - accuracy: 0.7416 - loss: 0.5349 - val_accuracy: 0.7676 - val_loss: 0.5287\n",
            "Epoch 4/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.7792 - loss: 0.4981 - val_accuracy: 0.7582 - val_loss: 0.5066\n",
            "Epoch 5/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.7810 - loss: 0.4754 - val_accuracy: 0.7676 - val_loss: 0.4750\n",
            "Epoch 6/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.7488 - loss: 0.5018 - val_accuracy: 0.7629 - val_loss: 0.5013\n",
            "Epoch 7/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.7608 - loss: 0.4694 - val_accuracy: 0.8005 - val_loss: 0.4732\n",
            "Epoch 8/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.7727 - loss: 0.4662 - val_accuracy: 0.7981 - val_loss: 0.4315\n",
            "Epoch 9/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 114ms/step - accuracy: 0.7692 - loss: 0.4615 - val_accuracy: 0.8310 - val_loss: 0.4336\n",
            "Epoch 10/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 112ms/step - accuracy: 0.7810 - loss: 0.4354 - val_accuracy: 0.8146 - val_loss: 0.4179\n",
            "Epoch 11/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.7982 - loss: 0.4255 - val_accuracy: 0.7840 - val_loss: 0.4378\n",
            "Epoch 12/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.7825 - loss: 0.4404 - val_accuracy: 0.8286 - val_loss: 0.4024\n",
            "Epoch 13/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.7900 - loss: 0.4054 - val_accuracy: 0.8263 - val_loss: 0.4086\n",
            "Epoch 14/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.8196 - loss: 0.3594 - val_accuracy: 0.8099 - val_loss: 0.3729\n",
            "Epoch 15/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 107ms/step - accuracy: 0.8146 - loss: 0.3676 - val_accuracy: 0.8192 - val_loss: 0.3862\n",
            "Epoch 16/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.8081 - loss: 0.3814 - val_accuracy: 0.8146 - val_loss: 0.4121\n",
            "Epoch 17/50\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.8310 - loss: 0.4028 - val_accuracy: 0.8216 - val_loss: 0.4205\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7899 - loss: 0.3961\n",
            "Validation Loss: 0.3729052245616913\n",
            "Validation Accuracy: 0.8098591566085815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.62      0.71       159\n",
            "           1       0.80      0.92      0.86       267\n",
            "\n",
            "    accuracy                           0.81       426\n",
            "   macro avg       0.81      0.77      0.78       426\n",
            "weighted avg       0.81      0.81      0.80       426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',  # Metric to monitor (e.g., 'val_loss' or 'val_accuracy')\n",
        "    patience=3,          # Number of epochs with no improvement to wait before stopping\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train_images, X_train_metadata],  # Input data (images and metadata)\n",
        "    y_train,  # Labels\n",
        "    validation_data=([X_val_images, X_val_metadata], y_val),  # Validation data\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping],  # Include the EarlyStopping callback here\n",
        ")\n",
        "\n",
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate([X_val_images, X_val_metadata], y_val)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_acc}\")\n",
        "\n",
        "# Predictions and classification report\n",
        "y_pred = (model.predict([X_val_images, X_val_metadata]) > 0.5).astype(int)  # Convert predictions to 0 or 1\n",
        "\n",
        "# Classification report (Precision, Recall, F1-Score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
